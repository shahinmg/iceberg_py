import dask.distributed
import dask.utils
import numpy as np
import planetary_computer as pc
import xarray as xr
from IPython.display import display
from pystac_client import Client
import geopandas as gpd
import requests
from pystac.extensions.eo import EOExtension as eo
from odc.stac import configure_rio, stac_load
%matplotlib inline

import matplotlib.pyplot as plt
import numpy as np



client = dask.distributed.Client()
configure_rio(cloud_defaults=True, client=client)
display(client)


resolution = 10


catalog = Client.open("https://planetarycomputer.microsoft.com/api/stac/v1",modifier=pc.sign_inplace)
hel_mel = gpd.read_file('/media/laserglaciers/upernavik/iceberg_py/geoms/helheim/melange_box.shp')


query = catalog.search(
    collections=["sentinel-2-l2a"],
    datetime="2023-07",
    query={"s2:mgrs_tile": dict(eq="24WWU"),
          "eo:cloud_cover": {"lt": 10}},
)

items = list(query.items())
print(f"Found: {len(items):d} datasets")


items
selected_item = sorted(items, key=lambda item: eo.ext(item).cloud_cover)[-1]
selected_item


selected_items = []
selected_items.append(selected_item)


query = catalog.search(
    collections=["sentinel-2-l2a"],
    datetime="2020-09",
    query={"s2:mgrs_tile": dict(eq="24WWU"),
          "eo:cloud_cover": {"lt": 10}},
)

items = list(query.items())
print(f"Found: {len(items):d} datasets")
selected_item = sorted(items, key=lambda item: eo.ext(item).cloud_cover)[0]
selected_item

print(
    f"Choosing {selected_item.id} from {selected_item.datetime.date()}"
    + f" with {selected_item.properties['eo:cloud_cover']}% cloud cover"
)


selected_items.append(selected_item)
selected_items


query = catalog.search(
    collections=["sentinel-2-l2a"],
    datetime="2018-05",
    query={"s2:mgrs_tile": dict(eq="24WWU"),
          "eo:cloud_cover": {"lt": 10}},
)

items = list(query.items())
print(f"Found: {len(items):d} datasets")
selected_item = sorted(items, key=lambda item: eo.ext(item).cloud_cover)[0]
selected_item

print(
    f"Choosing {selected_item.id} from {selected_item.datetime.date()}"
    + f" with {selected_item.properties['eo:cloud_cover']}% cloud cover"
)


xx = stac_load(
    items,
    bands=["red", "green", "blue", "nir"],
    resolution=resolution,
    chunks={"x": 2048, "y": 2048},
    patch_url=pc.sign,
    # force dtype and nodata
    dtype="uint16",
    nodata=0,
    geopolygon=hel_mel
)

print(f"Bands: {','.join(list(xx.data_vars))}")
display(xx)
xx.red.isel(time=0).plot()


selected_items.append(selected_item)
selected_items


query = catalog.search(
    collections=["sentinel-2-l2a"],
    datetime="2024-08",
    query={"s2:mgrs_tile": dict(eq="24WWU"),
          "eo:cloud_cover": {"lt": 10}},
)

items = list(query.items())
print(f"Found: {len(items):d} datasets")
selected_item = sorted(items, key=lambda item: eo.ext(item).cloud_cover)[3]
selected_item

print(
    f"Choosing {selected_item.id} from {selected_item.datetime.date()}"
    + f" with {selected_item.properties['eo:cloud_cover']}% cloud cover"
)


xx = stac_load(
    items,
    bands=["red", "green", "blue", "nir"],
    resolution=resolution,
    chunks={"x": 2048, "y": 2048},
    patch_url=pc.sign,
    # force dtype and nodata
    dtype="uint16",
    nodata=0,
    geopolygon=hel_mel
)

print(f"Bands: {','.join(list(xx.data_vars))}")
display(xx)
xx.red.isel(time=3).plot()


resolution = 10
SHRINK = 1
if client.cluster.workers[0].memory_manager.memory_limit < dask.utils.parse_bytes("4G"):
    SHRINK = 8  # running on Binder with 2Gb RAM

if SHRINK > 1:
    resolution = resolution * SHRINK

xx = stac_load(
    items,
    chunks={"x": 2048, "y": 2048},
    patch_url=pc.sign,
    resolution=resolution,
    # force dtype and nodata
    dtype="uint16",
    nodata=0,
)

print(f"Bands: {','.join(list(xx.data_vars))}")
display(xx)


selected_items.append(selected_item)
selected_items


query = catalog.search(
    collections=["sentinel-2-l2a"],
    datetime="2016-04",
    query={"s2:mgrs_tile": dict(eq="24WWU"),
          "eo:cloud_cover": {"lt": 10}},
)

items = list(query.items())
print(f"Found: {len(items):d} datasets")
selected_item = sorted(items, key=lambda item: eo.ext(item).cloud_cover)[1]
selected_item

print(
    f"Choosing {selected_item.id} from {selected_item.datetime.date()}"
    + f" with {selected_item.properties['eo:cloud_cover']}% cloud cover"
)


xx = stac_load(
    items,
    bands=["red", "green", "blue", "nir"],
    resolution=resolution,
    chunks={"x": 2048, "y": 2048},
    patch_url=pc.sign,
    # force dtype and nodata
    dtype="uint16",
    nodata=0,
    geopolygon=hel_mel
)

print(f"Bands: {','.join(list(xx.data_vars))}")
display(xx)
xx.red.isel(time=4).plot()


selected_items.append(selected_item)
selected_items



import pickle

with open('/media/laserglaciers/upernavik/iceberg_py/infiles/helheim/stac_items/helheim_stac_items.pkl', 'wb') as f:
    pickle.dump(selected_items, f)


xx = stac_load(
    items,
    bands=["red", "green", "blue", "nir"],
    resolution=resolution,
    chunks={"x": 2048, "y": 2048},
    patch_url=pc.sign,
    # force dtype and nodata
    dtype="uint16",
    nodata=0,
    geopolygon=hel_mel
)

print(f"Bands: {','.join(list(xx.data_vars))}")
display(xx)
xx.red.isel(time=0).plot()



def to_float(xx):
    _xx = xx.astype("float32")
    nodata = _xx.attrs.pop("nodata", None)
    if nodata is None:
        return _xx
    return _xx.where(xx != nodata)


def colorize(xx, colormap):
    return xr.DataArray(colormap[xx.data], coords=xx.coords, dims=(*xx.dims, "band"))


# like .astype(float32) but taking care of nodata->NaN mapping
nir = to_float(xx.nir)
red = to_float(xx.red)
ndvi = (nir - red) / (
    nir + red
)  # < This is still a lazy Dask computation (no data loaded yet)

# Get the 5-th time slice `load->compute->plot`
_ = ndvi.isel(time=1).compute().plot.imshow(size=7, aspect=1.2, interpolation="bicubic")


# xx.isel(time=4).compute().plot.imshow(size=7, aspect=1.2, interpolation="bicubic")

_ = (
    xx.isel(time=0)
    .to_array("band")
    .plot.imshow(
        col="band",
        size=4,
        vmin=0,
        vmax=4000,
    )
)



time=4
rgb = np.dstack((xx.red.isel(time=time).values,
                 xx.green.isel(time=time).values,
                 xx.blue.isel(time=time).values))
# Normalize the RGB data
rgb_norm = rgb / rgb.max()

# Display the normalized RGB image using plt.imshow
plt.imshow(rgb_norm)


xx.isel(time=0).odc.affine


items[0].assets['B02'].href


requests.head(items[0].assets['B02'].href).status_code



import rasterio.plot
with rasterio.open(items[0].assets['B02'].href) as dataset:
    rasterio.plot.show(dataset)


from rasterio.plot import show
import numpy as np

affine = xx.red.isel(time=time).odc.affine

#better for rasterio?
t = np.moveaxis(rgb_norm.T,1,-1)
show(t, transform=affine)


t.dtype


height, width = xx.red.isel(time=time).shape



from rasterio.features import geometry_mask, geometry_window


grid_path = '/media/laserglaciers/upernavik/iceberg_py/geoms/helheim/3x6_grid.shp'
grid = gpd.read_file(grid_path)
grid.geometry


from contextlib import contextmanager  
import rasterio
from rasterio import Affine, MemoryFile
from rasterio.enums import Resampling
from rasterio.windows import Window
import cv2
from segment_anything import SamPredictor, SamAutomaticMaskGenerator,sam_model_registry

import matplotlib.pyplot as plt
import numpy as np
from PIL import Image
import os
import torch



#https://rasterio.groups.io/g/main/topic/memoryfile_workflow_should/32634761
@contextmanager
def mem_raster(data, **profile):
    with MemoryFile() as memfile:
        with memfile.open(**profile) as dataset_writer:
            dataset_writer.write(data)
 
        with memfile.open() as dataset_reader:
            yield dataset_reader

def cv2Norm(band):
    img_u8 = cv2.normalize(band, None, 255, 0, cv2.NORM_MINMAX, cv2.CV_8U)
    return img_u8

profile_t = {'driver':'GTiff', 'count':3, 
                      'transform':affine, 'crs':32624, 
                      'width':t.shape[2], 'height': t.shape[1], 
                      'dtype':np.float64
}


grid2_path = '/media/laserglaciers/upernavik/iceberg_py/geoms/helheim/melange_box_grid_utm24.shp'
grid2 = gpd.read_file(grid2_path)

for geom in grid2.geometry:
    print(geom)


def sam_segment(image_chunk):
    FEATURE_OF_INTEREST = 'icebergs' #icebergs,crevasse,terminus,supraglacial_lakes,planet, sentinel-2, sentinel-1, timelapse
    MODEL_TYPE = 'vit_h'
    MODEL_WEIGHTS = 'sam_vit_h_4b8939.pth' # sam_vit_b_01ec64.pth,sam_vit_h_4b8939.pth,sam_vit_l_0b3195.pth
    OUTPUT_FOLDER = 'predict_no_prompt' # predict_with_prompt, predict_no_prompt
    
    BASE_PATH = f'/media/laserglaciers/upernavik/Helheim_ortho_photos/ortho_images/jpgs/'
    # OUTPUT_PATH = os.path.join(BASE_PATH,'%s'%(OUTPUT_FOLDER))
    OUTPUT_PATH = f'{BASE_PATH}/OUTPUT_FOLDER'
    fileName = '7P14_M42_A4545V_239_ortho.jpg'

    sam = sam_model_registry["%s"%(MODEL_TYPE)](checkpoint="/media/laserglaciers/upernavik/segment-anything/models/%s"%(MODEL_WEIGHTS))
    predictor = SamPredictor(sam)
    predictor.set_image(image_chunk)


    mask_generator = SamAutomaticMaskGenerator(sam)
    
    masks = mask_generator.generate(image_chunk)
    out_path = '/media/laserglaciers/upernavik/iceberg_py/outfiles/helheim/sam_output/2023_07_27.png'
    if FEATURE_OF_INTEREST == 'terminus':
        for num in range(len(masks)):
            im = Image.fromarray(masks[num]['segmentation'])
            im.save(f'{OUTPUT_PATH}/{fileName.split(".")[0]}{num}_predict.png')
    
    else:
        binary_pred_zeros = np.zeros_like(masks[1]['segmentation'])
        for num in range(len(masks)):
            # 25% or higher number of pixels are True, that means it is a potential representation of background
            # and not of icebergs
            if np.count_nonzero(masks[num]['segmentation'])>(0.25*(masks[num]['segmentation']).size):
                continue
            else:               
                binary_pred_zeros[masks[num]['segmentation']==1]=1
        im = Image.fromarray(binary_pred_zeros)
        # # im.save(f'{OUTPUT_PATH}/{fileName.split(".")[0]}_predict_{MODEL_TYPE}.png')
        # im.save(f'{out_path}')

    
    return im


grid2_path = '/media/laserglaciers/upernavik/iceberg_py/geoms/helheim/melange_box_grid_utm24.shp'
grid2 = gpd.read_file(grid2_path)
image_chunk_dict = {}
date = str(xx.red.isel(time=time).time.dt.date.data)

with mem_raster(t, **profile_t) as ds:
    for i, geom in enumerate(grid2.geometry): 
        window = geometry_window(ds, [geom])
        w = ds.read([1,2,3], window=window)
        win_transform = ds.window_transform(window)
        w2 = np.moveaxis(w,0,-1)
        # show(w,transform=win_transform)
        image_chunk_dict[win_transform] = w
        im = sam_segment(w2)
        
        nim = np.array(im)
        profile_out = {'driver':'GTiff', 'count':1, 
                      'transform':win_transform, 'crs':32624, 
                      'width':nim.shape[1], 'height': nim.shape[0], 
                      'dtype':np.float64
                        }
        out_name = f'{date}_helheim_{i}.tif'
        with rasterio.open(f'/media/laserglaciers/upernavik/iceberg_py/outfiles/helheim/sam_output/{out_name}', mode='w', **profile_out) as dst:
            dst.write(nim,1)









date = xx.red.isel(time=time).time.dt.date.compute()
str(xx.red.isel(time=time).time.dt.date.data)


fig, ax = plt.subplots(1,2)
ax[0].imshow(im)
ax[1].imshow(w2)


im.save('/media/laserglaciers/upernavik/iceberg_py/outfiles/helheim/sam_output/test2.png',"PNG")


type(im)


nim = np.array(im)


nim.shape





with rasterio.open('/media/laserglaciers/upernavik/iceberg_py/outfiles/helheim/sam_output/test2.tif', mode='w', **profile_out) as dst:
    dst.write(nim,1)


win_transform


w.shape


profile_out = {'driver':'GTiff', 'count':3, 
                      'transform':win_transform, 'crs':32624, 
                      'width':w.shape[2], 'height': w.shape[1], 
                      'dtype':np.float64
}
with rasterio.open('/media/laserglaciers/upernavik/iceberg_py/outfiles/helheim/sam_output/test2_rbg.tif', mode='w', **profile_out) as dst:
    dst.write(w[0,:,:],1)
    dst.write(w[1,:,:],2)
    dst.write(w[2,:,:],2)






